---
title: "Multiple-Platform Viewership Analysis"
author: "Xiao Liu"
date: "3/26/2019"
output: 
  html_document: 
    theme: readable
    toc: true
---
<style>
body {
text-align: justify}
</style>

```{r cache=TRUE, include=FALSE}
rm(list = ls()) # clean environment 
setwd('/Users/Xiao/Downloads/Sample_Data')
app = read.csv('app_data_sample.csv', na.strings=c("NA", "NaN", 'Null', " ", '')) # 797563*8
tv = read.csv('tv_data_sample.csv',na.strings=c("NA", "NaN", 'Null', " ", ''))  # 1062961*30
website = read.csv('web_data_sample.csv', na.strings=c("NA", "NaN", 'Null', " ", '')) # 33521*8
```

```{r cache=TRUE, include=FALSE}
# Load libraries
mypackages = c('dplyr', 'stringr', 'plotly', 'knitr', 'kableExtra', 'DT', 'klaR')
tmp = setdiff(mypackages, rownames(installed.packages()))
if(length(tmp) > 0) install.packages(tmp)
```

```{r cache=TRUE, include=FALSE}
library(dplyr)
library(stringr)
library(plotly) # interactive plotting
library(kableExtra)
library(knitr)
library(DT) # interactive table
library(klaR) # kmodes clustering
```

 
```{r cache=TRUE, include=FALSE}
                        ###  Rre-processing ###

                                 ## App


# 20170102   -> remove
if (length(unique(app$TIME_DIM_ID)) == 1) app$TIME_DIM_ID = NULL
# Only 1 value -> remove
if (unique(app$OS_DIM_ID) == 1) app$OS_DIM_ID = NULL
# Remove TOTAL_MINUTES that equals to 0    
app = app[-which(app$TOTAL_MINUTES == 0),]  # 796545*6


                                ## Website

# Only 1 value -> remove
website$TIME_DIM_ID = NULL
# Keep TOTAL_MINUTES that is at least 1    
website = website[which(website$TOTAL_MINUTES >= 1),]     # 15168

                                  ## TV

# Duplicate info as VIEW_DATE_ID -> remove
tv$VIEW_DATE = NULL

# Convert VIEW_DATE_ID to date
# Change column name to VIEW_DATE
tv$VIEW_DATE_ID = as.Date(as.character(tv$VIEW_DATE_ID), format="%Y%m%d")
colnames(tv)[2] = 'VIEW_DATE'

# Only one record 201701 -> remove
if (length(unique(tv$VIEW_WEEK_ID)) == 1) tv$VIEW_WEEK_ID = NULL
# Only one record Wk 01-02-2017  -> remove
if (length(unique(tv$VIEW_WEEK_DESC)) == 1)  tv$VIEW_WEEK_DESC = NULL

# Remove 'Wk' from AIR_WEEK
tv$AIR_WEEK = gsub("Wk ", "", tv$AIR_WEEK)
tv$AIR_WEEK = as.Date(tv$AIR_WEEK, format = '%m-%d-%Y')

# Remove DOW from AIR_DATE
# Convert to date format 
tv$AIR_DATE = str_sub(tv$AIR_DATE,-10,-1)
tv$AIR_DATE = as.Date(tv$AIR_DATE)

# DEVICE_TYPE all are TV ->remove
tv$DEVICE_TYPE = NULL

# STREAMING_SOURCE
tv$STREAMING_SOURCE = as.factor(tv$STREAMING_SOURCE)

# Code season 2 lovesick air date and air week as below
tv[which(tv$AIR_DATE== '0017-11-07'),'AIR_DATE'] = as.Date('2016-11-17')
tv[which(tv$AIR_WEEK== '0017-11-06'),'AIR_WEEK'] = as.Date('2016-11-14')

# Remove samples which have AIR_DATE after VIEW_DATE 
tv = tv[tv$AIR_DATE<=tv$VIEW_DATE,]     # 1045013 * 25

# Convert SAM_CHANNEL_NAME to factor
tv$SAM_CHANNEL_NAME = as.factor(tv$SAM_CHANNEL_NAME)

# Convert '00:00:00' to 10:30 PM 
actual_time = unique(tv[which(tv$AIR_DATE == '2017-01-01' & 
                  tv$SAM_CHANNEL_NAME == '-8533751760878745600' & 
                  tv$STREAMING_SOURCE == '-8728696470213803008' & 
                  tv$Q_PROGRAM_NAME == 'S-7/ E-6-The Walking Dead' & 
                  tv$AIR_TIME != '00:00:00'),'AIR_TIME'])
tv[which(tv$AIR_TIME == '00:00:00'),'AIR_TIME'] = as.factor(actual_time)

# Only keep records that have a ELAPSED_TIME at least 10% of the show time 
tv = tv[which(tv$SHOW_DURATION >= tv$ELAPSED_TIME),]
tv = tv[which(tv$ELAPSED_TIME/tv$SHOW_DURATION >= 0.1),]

# Convert SHOW_DURATION in minute unit
tv$SHOW_DURATION = tv$SHOW_DURATION/60000

# Convert ELAPSED_TIME in minute unit 
tv$ELAPSED_TIME = tv$ELAPSED_TIME/60000     #531172
```

# Introduction


## Project Introduction

In this project, I focused on exploring the data from a business intelligence standpoint. 

In the first part, I analyzed TV, App, and Website datasets seperately and summarized my findings in the form of table and plots. I also explored the connections among three datasets, trying to see what actional insights we can gain. Each of my analyses begins with a question, followed with approaches and data visualizations, and finally gives conclusions/recommendations. 

In the second part, I conducted audience segmentation and wrote about my thoughts about how segmentation can be improved if more data is given.

Lastly, I listed what I want to do in order to further explore the datasets if more time is given. 

<br>
-----------------------------------------------------------------------------------------------------------------------------------


## Brief Data Introduction


The TV dataset contains audience behavior information including view time, tv programs and network for each user in the week of 2017-01-02. It originally contains 1062961 observations and 30 variables. After data cleaning and manipulation such as removing unreasonable records, converting data types, and removing duplicate/useless columns, it contains 531172 observations and 26 variables (use id included).

The App data contains app usage information including App name, device used, and time used on each App for each user on 2017-01-02. It originally contains 797563 observations and 8 variables. After removing duplicate/useless columns and removing unreasonable records, it contains 796545 observations and 6 variables (use id included).

The original Web data contains website usage information including website name, device used, and time spent on each website for each user on 2017-01-02. It originally contains 33521 observations and 8 variables. Records with TOTAL_MINUTES less than 1 are removed from the dataset. After removing duplicate/useless columns and removing records with unreasonable records, it contains 15168 observations and 7 variables (use id included).

-----------------------------------------------------------------------------------------------------------------------------------


# Exploratory Data Analysis and Data Understanding

<br>

## TV Usage

### How are audiences distriuted by day of week?

I first wanted to see the if number of TV audience and watching time differs by day of week. Number of unique audience on each day, total time spent(in hrs) on each day, and average time spent(in hrs) are calculated and summarized in the following table. I expect that Friday and Weekends will have more audiences and average spent time on TV than any day from Monday to Thursday.
<br>
<br>
Please note that number of TV audience is calculated by counting the number of unique user id to prevent duplicate counts for users. 

```{r echo=FALSE, cache=TRUE}
# number of TV audience by DOW 
df_audience = tv %>% group_by(tv$VIEW_DOW) %>% summarise(n_audience = n_distinct(USERS_META_ID))
colnames(df_audience)[1] = 'VIEW_DOW'
```

```{r echo=FALSE, cache=TRUE}
# total time spent on TV by DOW
df_time = tv %>% group_by(tv$VIEW_DOW) %>% summarise(total_time = sum(as.numeric(ELAPSED_TIME)))
df_time$total_time = df_time$total_time/60 # convert to hr unit
colnames(df_time) = c('VIEW_DOW','total_time_hr')

# average watching time per audience by DOW
df_average = data.frame(df_time$VIEW_DOW, df_time$total_time_hr/df_audience$n_audience)
colnames(df_average) = c('VIEW_DOW', 'average_time_spent')
df_average$VIEW_DOW = ordered(df_average$VIEW_DOW, levels=c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
```

```{r echo=FALSE, cache=TRUE}
# merge three data and create an interactive table using DT library
audience_time = merge(df_audience,df_time)
audience_time = merge(audience_time,df_average)
audience_time$total_time_hr = format(round(audience_time$total_time_hr,2),nsmall = 2)
audience_time$average_time_spent = format(round(audience_time$average_time_spent,2),nsmall = 2)
DT::datatable(audience_time, rownames = FALSE)
```


From the above table we can see that in the week of 2017-01-02, number of audience are very similar on each day - around 12k. Thursday, Sunday and Friday have the most audiences.<br>

The total amount of hours spent on TV is from around 25k to 35k with Sunday (34907 hours) and Saturday (31565) being the most and second most.<br>

Sunday and Saturday also had the top two average view time: on average, an audience spent 2.85 and 2.62 hours on Sunday and Saturday, respectively. 

```{r echo=FALSE, cache=TRUE}
end = audience_time[which(audience_time$VIEW_DOW == 'Sunday' | audience_time$VIEW_DOW == 'Saturday'),]
time1 = sum(as.numeric(end$total_time_hr))/sum(end$n_audience)

day = audience_time[-which(audience_time$VIEW_DOW == 'Sunday' | audience_time$VIEW_DOW == 'Saturday'),]
time2 = sum(as.numeric(day$total_time_hr))/sum(end$n_audience)

dif = (sum(as.numeric(end$total_time_hr))/sum(end$n_audience) - sum(as.numeric(day$total_time_hr))/sum(day$n_audience) ) * 60
```

**People watched TV about 30 minutes more per day on weekends(2.73 hrs) than on weekdays(2.23 hrs).** 

**To my suprise, Monday is on the third most total hours spent (30531.14 hours) and it also has the third most average view time, 2.53 hours.**

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



### How are LIVE audiences distributed by air day part?

To see how audience behaviors differ by part of day the show is on air, we need to know audiences' view time. However since we don't have exact view time information in the dataset, I only analyzed the LIVE audiences whose view time can reference Air time.

I first created a subset for LIVE audiences and then counted the number of users in each AIR_DAY_PART.
<br>
Please note that number of TV audience is calculated by counting the number of unique user id to prevent duplicate counts for users. 

```{r echo=FALSE, cache=TRUE}
live = tv[which(tv$TIMESHIFT_INDICATOR_DESC == 'live'),]
live_airday = live %>% group_by(live$AIR_DAY_PART_DESC) %>% summarise(n_audience = n_distinct(USERS_META_ID))

colnames(live_airday) = c('AIR_DAY_PART_DESC','Count')

live_airday$AIR_DAY_PART_DESC = ordered(live_airday$AIR_DAY_PART_DESC, levels=c('Overnight (2AM-5AM)', "Late fringe (11:30PM-2AM)", "Late news (11PM-11:30PM)", "Prime (8PM-11PM)","Prime access (7PM-8PM)","Early news or Access Plus (5PM-7PM)","Early fringe (3PM-5PM)","Daytime (9AM-3PM)","Early Morning (5AM-9AM)"))

airtime_wk = live %>% group_by(live$AIR_DAY_PART_DESC, live$WEEK_DAY_END) %>% summarise(n_audience = n_distinct(USERS_META_ID))
colnames(airtime_wk) = c('Air_Day_Part','Weekdays_Weekend','Number_of_Audience')

airtime_wd = airtime_wk[which(airtime_wk$Weekdays_Weekend == 'Weekday'),]
airtime_end = airtime_wk[which(airtime_wk$Weekdays_Weekend == 'Weekend'),]

df = data.frame(live_airday$AIR_DAY_PART_DESC,live_airday$Count,airtime_wd$Number_of_Audience,airtime_end$Number_of_Audience)

colnames(df) = c('Air_Day_Part','Number_of_Audience', 'Weekday', 'Weekends')
df$Air_Day_Part = ordered(df$Air_Day_Part, levels=c('Overnight (2AM-5AM)', "Late fringe (11:30PM-2AM)", "Late news (11PM-11:30PM)", "Prime (8PM-11PM)","Prime access (7PM-8PM)","Early news or Access Plus (5PM-7PM)","Early fringe (3PM-5PM)","Daytime (9AM-3PM)","Early Morning (5AM-9AM)" ))

# df$p1 = round(df$Number_of_Audience/sum(df$Number_of_Audience),3)
# df$p2 =  round(df$Weekday/sum(df$Weekday),3)
# df$p3 = round(df$Weekends/sum(df$Weekends),3)
```

<center>

```{r echo=FALSE, cache=TRUE}
plot_ly(df, y = ~Air_Day_Part, x= ~Number_of_Audience, type='bar', orientation = 'h') %>% layout(title = 'Number of Live Audience by Air Day Part', yaxis = list(title = 'Air Day Part'), xaxis = list(title = 'Number of Audience'), font = list(size = 10))
```

</center>

We can see that **during a day, most audiences watch Live TV during Prime time(8pm - 11pm). Then it follows by Daytime(9am - 3pm) and Early Fringe(3pm-5pm). Overnight have the least number of audiences throughout the day.**

-----------------------------------------------------------------------------------------------------------------------------------


### How are LIVE audiences distributed by air day part on weekdays and weekends?


If calculate average number of LIVE audience in weekdays and weekends seperately as below, we can see that **although prime hours were peak TV viewing times on both weekend days and weekdays, number of audience was greater on weekend days beginning from 9PM and continuing until 5AM. In another way, number of audience on weekday is greater than that on weekday only during Early Morning.**


<center>
```{r echo=FALSE, cache=TRUE}
df$Weekday = round(df$Weekday/5,0)
df$Weekends = round(df$Weekends/2,0)

plot_ly(df, y = ~Air_Day_Part, x= ~Weekday, type='bar', orientation = 'h', name = 'Weekday') %>%
  add_trace(x = ~Weekends, name = 'Weekends') %>% layout(title = 'Number of Live Audience by Air Day Part', yaxis = list(title = 'Air Day Part'), xaxis = list(title = 'Number of Audience'), font = list(size = 10))
```

</center>



----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### What are the most popular shows for LIVE audiences?

```{r echo=FALSE, cache=TRUE}
genre_count = data.frame(table(tv$MASTER_GENRE_DESC))
colnames(genre_count) = c('Genre', 'Count')
```

```{r echo=FALSE, cache=TRUE}
live_airday = tv[which(tv$TIMESHIFT_INDICATOR_DESC == 'live'),]
genre_live = live_airday %>% group_by(live_airday$MASTER_GENRE_DESC) %>% count()
colnames(genre_live) = c('Genre', 'Count_Live')
genre_live_count = merge(genre_count,genre_live)
genre_live_count$Live_Percent = scales::percent(genre_live_count$Count_Live/genre_live_count$Count)

datatable(genre_live_count, options = list(pageLength = 5), rownames = F)
```

<br>
<br>
Comedy, Drama, Reality, News and Children are the top 5 genres which have the most number of audiences. Spanish language, Sports talk, and Art/Music are the bottom 3 genres which have the least number of audiences.

**Although Comedy has the largest audience group(109k), only 47.9% of them watched the shows on LIVE. However, although only 36k audiences watched Sports, 83% of them watched the shows on LIVE. Similar thing happened to Talk/Variety: out of 36k audiences who watched them, 72% of them watched on LIVE.**


-----------------------------------------------------------------------------------------------------------------------------------


### What is the distribution of video view platforms?

Today's program content is viewed on more than just television sets. Consumers are watching via the Internet and on mobile devices, in-home and out-of-home, live and time-shifted. Therefore, I would like to see how video view platform is distributed among our audience.

To approach this problem, I grouped the data by video platform categories and then counted the number of unique users indicated by unique USER_META_ID.


<center>
```{r, echo=F, message=FALSE, warning=FALSE, paged.print=FALSE, cache=TRUE}
platform = tv %>% group_by(tv$VIDEO_VIEW_PLATFORM) %>% summarise(User_Number = n_distinct(USERS_META_ID)) 

colnames(platform)[1] = 'Video_View_Platform'
plot_ly(data = platform, values = ~User_Number, labels = ~Video_View_Platform, type='pie' ) %>% layout(title = "Number of Users by Video View Platform")
```

</center>

I chose *pie chart* here to show each population because it shows both the proportion and number of each population, which enables us to compare 4 populations easily. We can see that around 60% of audiences watched TV through either Live or DVR. 

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


## App Usage

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### How much time is spent on different categories of Apps?


To approach this problem, I calculated the total time spent on each App category. Then I calculated the proportion of total time spent on each App category. There are 17 categories such as Food&Drink, Family&Kids, Educational took up less than 5% of the total time, therefore they are categorized as 'Others'.

The following pie chart can clearly show the proportion of time spent in each App category of the total time.

<center>

```{r echo=FALSE, cache=TRUE}
cate_time = app %>% group_by(app$COMMON_CATEGORY_DESC) %>% summarise(Time_Spent = sum(TOTAL_MINUTES))
colnames(cate_time)[1] = 'App_Category' 
cate_time$p = cate_time$Time_Spent/sum(cate_time$Time_Spent)
cate_time = cate_time%>% arrange(p)

# convert App_Category to 'Others' for apps that have Time_Spent<5% of total time spent 
ts = sum(cate_time[c(1:17),'Time_Spent'])
other = data.frame("Others", ts)
names(other) = c('App_Category', 'Time_Spent')

df1 = rbind(cate_time[c(18:25),c(1,2)],other)

plot_ly(df1, labels = ~App_Category, values = ~Time_Spent) %>%
   add_pie(hole = 0.6) %>% layout(title = "Time Spent on App by App Category",  showlegend = F,
                                  xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
          yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
```

</center>

**From the above pie chart we can see tha Social(18.5%) and Entertainment&Lifestyle(13.8%) are the major App categories. Then it follows Email&Communication, Misc, and Browser.**


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### Among Entertainment&Lifestyle, what are the major Apps used?
<br>
I paid extra attention on Entertainment&Lifestyle Apps because it contains streaming TV services and video platforms such as Youtube, Netflix, Hulu, Roku, Hbo Go and so on. Why is this important? 

From what Los Angelas Times mentioned, 'while the majority of viewers watch the old-fashioned way — live and seated in front of a TV screen — new technologies are rapidly transforming the way programming is consumed. The upending of television is being led by digital video recorders, video on-demand and streaming sites such as Netflix, Hulu and Amazon that can be watched on mobile phones and tablets as well'.[https://www.latimes.com/entertainment/tv/la-et-st-tv-section-ratings-20141123-story.html] 

**This indicates since more audiences tend to watch shows using their mobile devices, it becomes hard to track users' watching behaviors and measure their content consumptions, and therefore challenged to create completed user profile.** 

Therefore, I looked at the App consumption within Entertainment&Lifestyle and see if our users spent much time on streaming services on their mobile devices. 
<br>
```{r echo=FALSE, cache=TRUE}
entertainment = app[which(app$COMMON_CATEGORY_DESC == 'Entertainment & Lifestyle'),]

len = entertainment %>% group_by(entertainment$GROUP_TITLE_DESC) %>% summarise(User_Number = n_distinct(USERS_META_ID))  
colnames(len)[1] = 'App_Name'

time = entertainment %>% group_by(entertainment$GROUP_TITLE_DESC) %>% summarise(total_time = sum(TOTAL_MINUTES)) 
colnames(time) = c('App_Name', 'Total_Time')

time_len = merge(time,len)

time_len$Average_Time = round(time_len$Total_Time/time_len$User_Number,0)

time_len = time_len[which(time_len$User_Number >= 10 & time_len$Average_Time >=5),]
time_len$Time_Group = ifelse(time_len$Average_Time <= 10, '5-10 mins',
                             ifelse(time_len$Average_Time > 10 & time_len$Average_Time <= 20, '11-20 mins',
                                    ifelse(time_len$Average_Time > 20 & time_len$Average_Time <=30,'21-30 mins',
                                           ifelse(time_len$Average_Time > 30 & time_len$Average_Time <=40, '31-40 mins',
                                                  ifelse(time_len$Average_Time > 40 & time_len$Average_Time <= 50, '41-50 mins','51-60 mins')))))

time_len$Time_Group = ordered(time_len$Time_Group, levels = c("5-10 mins" ,"11-20 mins","21-30 mins","31-40 mins", "41-50 mins","51-60 mins"))

datatable(time_len, rownames = F)
```

<br>
<br>

There are many Apps within Entertainment&Lifestyle. Here I am only picking up a few popular streaming services and look at users' time consumption on them. 
<br>

On 2017-01-02,

* 3163 users used Youtube and spent 21 minutes on it on average.
* 555 users used Netflix and spent 23 minutes on it on average.
* 148 users used Hulu Plus and spent 14 minutes on it on average. 
* 53 users used Youtube Kids and spent 38 minutes on it on average.
* 80 users used Roku and spent 18 minutes on it on average. 
* 44 users used Entertainow Tv Mobile and spent 41 minutes on it on average. 
* 45 users used Lifestylz.tv and spent 36 minutes on it on average. 

<br>
This is not a completed list for streaming services and video platforms, however it already shows that many users spent much time on them, taking the market share from traditional TV viewing.
<br>

**Cross-device tracking can make it possible to get more accurate statistics of the users and comprehensive info about the users since users' identities are not split into pieces over multiple devices(cabke TV, streaming services, etc). For our case, if we have data on audience view information such as program information, view time, and elspsed time collected from streaming TV apps and video platform Apps, we will be able to better analyze users' viewing behavior and create customized marketing strategies for different audiences, e.g. recommend customized tv programs and promotion advertisements.**


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

## Website Usage


### How is Website Usage distributed by Day Part?

```{r include=FALSE,cache=TRUE}
# Bin HOUR_PART to AIR_DAY_PART_DESC from TV data
website$day_part = case_when(
  website$HOUR_PART_DESC %in% c('05:00 PM -05:30 PM','05:30 PM -06:00 PM','06:30 PM -07:00 PM') ~ 'Early news or Access Plus (5PM-7PM)',
website$HOUR_PART_DESC %in% c('07:00 PM -07:30 PM', '07:30 PM -08:00 PM') ~ 'Prime access (7PM-8PM)',
website$HOUR_PART_DESC %in% c('08:00 PM -08:30 PM','08:30 PM -09:00 PM','09:30 PM -10:00 PM', '10:00 PM -10:30 PM', '10:30 PM -11:00 PM') ~ 'Prime (8PM-11PM)',
website$HOUR_PART_DESC %in% c('11:30 PM -12:00 AM','12:00 AM -12:30 AM','12:30 AM -01:00 AM', '01:00 AM -01:30 AM', '01:30 AM -02:00 AM') ~ 'Late fringe (11:30PM-2AM)',
website$HOUR_PART_DESC %in% c('02:00 AM -02:30 AM','02:30 AM -03:00 AM','03:00 AM -03:30 AM', '03:30 AM -04:00 AM', '04:30 AM -05:00 AM') ~ 'Overnight (2AM-5AM)',
website$HOUR_PART_DESC %in% c('05:00 AM -05:30 AM','05:30 AM -06:00 AM','06:30 AM -07:00 AM', '07:30 AM -08:00 AM', '08:30 AM -09:00 AM') ~ 'Early Morning (5AM-9AM)',

website$HOUR_PART_DESC %in% c('09:00 AM -09:30 AM', '09:30 AM -10:00 AM' ,'10:00 AM -10:30 AM','10:30 AM -11:00 AM', '11:30 AM -12:00 PM', '12:00 PM -12:30 PM', '12:30 PM -01:00 PM' ,'01:00 PM -01:30 PM', '01:30 PM -02:00 PM', '02:00 PM -02:30 PM', '02:30 PM -3:00 PM') ~ 'Daytime (9AM-3PM)',

website$HOUR_PART_DESC %in% c('11:00 PM -11:30 PM') ~'Late news (11PM-11:30PM)',

TRUE ~ 'Early fringe (3PM-5PM)')
```

```{r echo=FALSE,cache=TRUE}
web_hour = website %>% group_by(website$day_part) %>% summarise(Total_Time = sum(TOTAL_MINUTES))
web_ppl = website %>% group_by(website$day_part) %>% summarise(Count = n_distinct(USERS_META_ID))
web_hour = web_hour %>% mutate(web_ppl$Count)
web_hour = web_hour  %>% mutate(
  round(web_hour$Total_Time/web_hour$`web_ppl$Count`,1)
  )
colnames(web_hour) = c('Day_Part', 'Total_Time', 'Number_User','Average_Time')

web_hour$Day_Part = ordered(web_hour$Day_Part, levels=c('Overnight (2AM-5AM)', "Late fringe (11:30PM-2AM)", "Late news (11PM-11:30PM)", "Prime (8PM-11PM)","Prime access (7PM-8PM)","Early news or Access Plus (5PM-7PM)","Early fringe (3PM-5PM)","Daytime (9AM-3PM)","Early Morning (5AM-9AM)" ))
datatable(web_hour, rownames = FALSE)
```

Note: Time is in minutes.

Most users spent time on Websites during 9AM to 5PM, and on average, each user spent the most time during this period of time as well. 



### Are there any difference between web usage and TV usage on different day parts?


The results from above analysis makes me wonder whether there is a difference between web usage and TV usage on different day parts. Therefore, I further created bar charts to compare the usages below: 


```{r include=FALSE}
# Subset TV so it only contains data of 2017-01-02
tv_0102 = tv[which(tv$VIEW_DATE == '2017-01-02'),]  #77417
# Select LIVE audience
tv_0102 = tv_0102[which(tv_0102$TIMESHIFT_INDICATOR_DESC == 'live'),] #44793
tv_hour = tv_0102 %>% group_by(tv_0102$AIR_DAY_PART_DESC) %>% summarise(Total_Time_TV = sum(ELAPSED_TIME))
colnames(tv_hour)[1] = 'Air_Day_Part'
tv_user = tv_0102 %>% group_by(tv_0102$AIR_DAY_PART_DESC) %>% summarise(TV_User = n_distinct(USERS_META_ID))

```


```{r include=FALSE}
tv_web = merge(tv_hour,web_hour,by.x = 'Air_Day_Part', by.y = 'Day_Part')
tv_web$TV_User = tv_user$TV_User
tv_web$TV_Avg_Time = round(tv_web$Total_Time_TV/tv_web$TV_User,1)
tv_web$Air_Day_Part = ordered(tv_web$Air_Day_Part, levels=c('Overnight (2AM-5AM)', "Late fringe (11:30PM-2AM)", "Late news (11PM-11:30PM)", "Prime (8PM-11PM)","Prime access (7PM-8PM)","Early news or Access Plus (5PM-7PM)","Early fringe (3PM-5PM)","Daytime (9AM-3PM)","Early Morning (5AM-9AM)" ))
```

<center>
```{r echo=FALSE}
plot_ly(tv_web, y = ~Air_Day_Part, x= ~TV_Avg_Time, type='bar', orientation = 'h', name = 'TV') %>% add_trace(tv_web, x= ~Average_Time, name = 'Web') %>%
  layout(title = 'Average Time Spent on TV and Website', yaxis = list(title = 'Air Day Part'), xaxis = list(title = 'Average Time Spent (mins)'), font = list(size = 10)) 
```

</center>

From above bar chart we can see that on 2017/01/02, our participates who watched LIVE TV spent much more time on TV than website on all day parts. Day time is most liked for both TV viewers and website viewers.
<br>
Please notice that our data for website usage is only for 2017-01-02, so the above conclusion can be very biased and therefore the conclusion may applicable for other times. 


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### How time was consumed on different websites?

To answer this question, I calculated the total time spent, number of users, and average time spent on each website.


```{r echo=FALSE}
web_min =  website %>% group_by(website$PRIMARY_DOMAIN_DESC) %>% summarise(Total_Minutes = sum(TOTAL_MINUTES))
n_user = website %>% group_by(website$PRIMARY_DOMAIN_DESC) %>% summarise(n_user = n_distinct(USERS_META_ID))
web_min = merge(web_min,n_user)
web_min$Avg_Time = round(web_min$Total_Minutes/web_min$n_user,1)
colnames(web_min)[1] = 'Website'
datatable(web_min, rownames = FALSE, options = list(pageLength = 5))
```


* Facebook, Google, Amazon, Graigslist and Youtube are the top 5 websites browsed in terms of total time. 
* Google, Facebook, Amazon, Wiki, and Perksplus are the top 5 websites that have the most users.

Our data is limited in the sense that we only know what webpage users browsed but NOT the content they looked at(not sure if it's legal). For example, if we know that a user checked Twitter and read about discussions about a recent movie, it is likely that this user is interested in the movie.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


```{r eval=FALSE, include=FALSE}

#If we subset our data so that it contains at least 5% of total website users, we can see below that only 6 #websites left:
# At least 5% of total users used
df2 = web_min[which(web_min$n_user> 0.05*length(unique(website$USERS_META_ID))),]
colnames(df2)[1] = 'Website'
datatable(df2)
```


# Audience Segmentation 

```{r eval=FALSE, include=FALSE}
set.seed(123)
# Select variables as clustering references
tv1 = tv %>% 
  dplyr::select(USERS_META_ID, AIR_DAY_PART_DESC, MASTER_GENRE_DESC,
                VIDEO_VIEW_PLATFORM,SYNDICATION_GROUP, 
                SHOW_DURATION, ELAPSED_TIME)

tv1[which(is.na(tv1$MASTER_GENRE_DESC)), 'MASTER_GENRE_DESC'] = 'Other'
tv1$ELAPSED_TIME  = log(tv1$ELAPSED_TIME)
tv1$SHOW_DURATION = log(tv1$SHOW_DURATION)
tv1 = distinct(tv1)  
```


```{r cache=TRUE, include=FALSE}
# Select variables as clustering references
tv2 = tv %>% 
  dplyr::select(AIR_DAY_PART_DESC, AIR_DOW, TIMESHIFT_INDICATOR_DESC, MASTER_GENRE_DESC,
                VIDEO_VIEW_PLATFORM, SYNDICATION_GROUP, PROGRAM_NAME)
tv2 = tv2 %>% mutate(p = round(tv$ELAPSED_TIME/tv$SHOW_DURATION,1))
# Get duplicated rows
dist = rownames(distinct(tv2))
tv3 = tv2[!rownames(tv2) %in% dist, ]

# Add cluster ID to data for duplicated rows
d = transform(tv3, Cluster_ID = as.numeric(interaction(AIR_DAY_PART_DESC, AIR_DOW, TIMESHIFT_INDICATOR_DESC, MASTER_GENRE_DESC, VIDEO_VIEW_PLATFORM, SYNDICATION_GROUP, PROGRAM_NAME, p)))

d = d[duplicated(d),]


```

Given the background that at Viacom, the focus of our business is to engage global audiences and deliver compelling content to our fans across all platforms, audience segmentation seems to be a topic that deserves much focus. In this project, I measured audience behavior by program info from TV data. To be more specific, I selected AIR_DAY_PART_DESC, AIR_DOW, TIMESHIFT_INDICATOR_DESC, MASTER_GENRE_DESC, VIDEO_VIEW_PLATFORM, SYNDICATION_GROUP, PROGRAM_NAME from TV data as well as a new feature which is percentage of time watched for a show (ELAPSED_TIME/SHOW_DURATION). Audiences were clustered into the same group only if all of these features of them are same.




## Other thoughts on Audience Segmentation

<br>

1. Audience Info

**If we have viewing data along with audiences'demographic and psychographic profiles, we would be able to better picture our audiences and therefore building an more accurate audience segmentation model.** For example, for two people B and C who have the same gender, age level and occupation as well as some overlapped TV programs subscription, it is likely that they share similar tastes on TV shows. A TV show that B likes might also be interesting to C and vice versa. Therefore, based on user similarities, we can taylor out content recommendations for users.

<br>

2. Social Media Data

* Social media data can also help with andience segmentation. For example, if we know person A liked a Facebook page about a sitcom that is about to show LIVE next month. It is likely that A likes this sitcom and wants to watch the show. Therefore, we can send A relevant offers and advertisements.

* Another thing about social media is that we can perform **sentiment analysis** on users' comments on TV programs to see their opinions on them. If we have enough reviews data, we can learn each person or groups preference, and therefore recommending taylored contents.

<br>

3. Purchasing Behavior Data


If we have users' purchasing behavior data, we can estimate how much an audience is worth to our company by calculating **customer lifetime value (CLV)** by means of Recency-Frequency-Monetary framework. We can then cluster users in terms of their CLV and loyalty and create targeted market plans (ads, campaigns, etc.) for different user groups.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


# What I would do if more time is given...

I would like to explore the relations of three data sources.
